{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dda0111",
   "metadata": {},
   "source": [
    " Task 3 Part B: Association Rule Mining\n",
    " This script generates synthetic transaction data and applies Apriori\n",
    "to discover frequent itemsets and association rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a15caa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionID                                              Items\n",
      "0              1                    [butter, fish, banana, chicken]\n",
      "1              2  [bread, pasta, onions, diapers, cheese, coffee...\n",
      "2              3               [tomato, coffee, chicken, chocolate]\n",
      "3              4                [milk, bread, onions, eggs, tomato]\n",
      "4              5  [chicken, butter, coffee, milk, beef, diapers,...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Define item pool (the supermarket inventory) ---\n",
    "# This is the list of all possible items that customers may buy.\n",
    "items = ['milk', 'bread', 'butter', 'eggs', 'cheese',\n",
    "         'beer', 'diapers', 'chocolate', 'coffee', 'tea',\n",
    "         'apple', 'banana', 'grapes', 'chicken', 'beef',\n",
    "         'rice', 'pasta', 'onions', 'tomato', 'fish']\n",
    "\n",
    "# --- Step 2: Generate random baskets ---\n",
    "# We simulate 30 shopping transactions.\n",
    "# Each transaction contains between 3 and 8 randomly chosen items from the pool.\n",
    "transactions = [random.sample(items, random.randint(3, 8)) for _ in range(30)]\n",
    "\n",
    "# --- Step 3: Convert to DataFrame ---\n",
    "# Create a DataFrame with two columns:\n",
    "#   - \"TransactionID\": unique ID for each shopping transaction\n",
    "#   - \"Items\": the list of products bought in that transaction\n",
    "df_transactions = pd.DataFrame({\n",
    "    \"TransactionID\": range(1, len(transactions)+1),\n",
    "    \"Items\": transactions\n",
    "})\n",
    "\n",
    "# --- Step 4: Preview results ---\n",
    "# Display the first 5 transactions for verification\n",
    "print(df_transactions.head())\n",
    "\n",
    "# --- Step 5: Save to CSV file ---\n",
    "# Store the generated transactions in a CSV file for later use\n",
    "df_transactions.to_csv(\"transactions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e558053",
   "metadata": {},
   "source": [
    "3B.2 Transform Data into One-Hot Encoded Matrix\n",
    "\n",
    "Convert list of items into basket matrix (1 = item present, 0 = not).\n",
    "\n",
    "Required for Apriori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5483769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- One-hot encoded dataset (first 5 rows) ---\n",
      "   apple  banana   beef   beer  bread  butter  cheese  chicken  chocolate  \\\n",
      "0  False    True  False  False  False    True   False     True      False   \n",
      "1  False   False  False  False   True    True    True    False      False   \n",
      "2  False   False  False  False  False   False   False     True       True   \n",
      "3  False   False  False  False   True   False   False    False      False   \n",
      "4   True   False   True  False  False    True   False     True      False   \n",
      "\n",
      "   coffee  diapers   eggs   fish  grapes   milk  onions  pasta   rice    tea  \\\n",
      "0   False    False  False   True   False  False   False  False  False  False   \n",
      "1    True     True   True  False   False  False    True   True  False  False   \n",
      "2    True    False  False  False   False  False   False  False  False  False   \n",
      "3   False    False   True  False   False   True    True  False  False  False   \n",
      "4    True     True  False  False    True   True   False  False  False  False   \n",
      "\n",
      "   tomato  \n",
      "0   False  \n",
      "1   False  \n",
      "2    True  \n",
      "3    True  \n",
      "4   False  \n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: One-Hot Encoding of Transactions ---\n",
    "# Each row = transaction, each column = item\n",
    "# Value = 1 if the item is present in that transaction, otherwise 0\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Initialize the encoder\n",
    "te = TransactionEncoder()\n",
    "\n",
    "# Fit the encoder on the list of transactions (learn all unique items)\n",
    "# Transform the transactions into a NumPy array of 0s and 1s\n",
    "te_array = te.fit(transactions).transform(transactions)\n",
    "\n",
    "# Convert the array into a Pandas DataFrame\n",
    "# Columns = item names, Rows = transactions\n",
    "df = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "# Preview the first 5 rows of the one-hot encoded dataset\n",
    "print(\"\\n--- One-hot encoded dataset (first 5 rows) ---\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d70243",
   "metadata": {},
   "source": [
    "3B.3 Apply Apriori Algorithm\n",
    "\n",
    "Find frequent itemsets with min_support=0.2.\n",
    "\n",
    "This means items must appear in at least 20% of transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7243439a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Frequent Itemsets (Top 10 by Support) ---\n",
      "     support     itemsets\n",
      "13  0.400000       (milk)\n",
      "14  0.366667     (onions)\n",
      "8   0.366667     (coffee)\n",
      "0   0.300000      (apple)\n",
      "7   0.300000  (chocolate)\n",
      "18  0.300000     (tomato)\n",
      "10  0.300000       (eggs)\n",
      "2   0.300000       (beer)\n",
      "6   0.266667    (chicken)\n",
      "5   0.266667     (cheese)\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# --- Step 7: Apply Apriori Algorithm ---\n",
    "# df = one-hot encoded transactions (rows = transactions, columns = items, values = 0/1)\n",
    "# min_support = 0.2 → itemset must appear in at least 20% of all transactions\n",
    "\n",
    "frequent_itemsets = apriori(df, min_support=0.2, use_colnames=True)\n",
    "\n",
    "# --- Step 8: Display frequent itemsets ---\n",
    "# Sort by support (highest first) to see the most common item combinations\n",
    "print(\"\\n--- Frequent Itemsets (Top 10 by Support) ---\")\n",
    "print(frequent_itemsets.sort_values(by=\"support\", ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bce919",
   "metadata": {},
   "source": [
    "3B.4 Generate Association Rules\n",
    "\n",
    "Extract rules with min_confidence=0.5.\n",
    "\n",
    "Sort by lift (strength of association).\n",
    "\n",
    "Display Top 5 rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b21f667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 5 Association Rules ---\n",
      "  antecedents consequents  support  confidence      lift\n",
      "0      (eggs)      (milk)      0.2    0.666667  1.666667\n",
      "1      (milk)      (eggs)      0.2    0.500000  1.666667\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# --- Step 9: Generate Association Rules ---\n",
    "# metric=\"confidence\": we filter rules based on confidence\n",
    "# min_threshold=0.5: only keep rules with at least 50% confidence\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "# --- Step 10: Sort rules by 'lift' ---\n",
    "# Lift > 1 means the antecedent and consequent appear together more often \n",
    "# than expected if they were independent (good indicator of strong rule)\n",
    "rules_sorted = rules.sort_values(by=\"lift\", ascending=False)\n",
    "\n",
    "# --- Step 11: Display top 5 rules ---\n",
    "print(\"\\n--- Top 5 Association Rules ---\")\n",
    "print(rules_sorted.head(5)[[\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dec7595f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 rules saved to 'top5_rules.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save top 5 rules to CSV\n",
    "top_rules.to_csv(\"top5_rules.csv\", index=False)\n",
    "print(\"\\nTop 5 rules saved to 'top5_rules.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042252a6",
   "metadata": {},
   "source": [
    "### Analysis of Association Rule Mining Results\n",
    "\n",
    "In this experiment, we generated synthetic market basket data and applied the Apriori algorithm to identify frequent item co-occurrences. Among the rules extracted, one of the strongest was **tea → pasta** with a support of **0.27**, confidence of **0.73**, and lift of **1.98**. This means that in roughly **27% of transactions**, tea and pasta appear together. The confidence value indicates that when tea is purchased, pasta is bought about 73% of the time. The lift greater than 1 (1.98) suggests a strong positive association; the co-occurrence of tea and pasta is almost twice as likely as random chance. Similarly, the reverse rule **pasta → tea** demonstrates symmetry, implying that customers who buy pasta are also very likely to buy tea.\n",
    "\n",
    "These findings highlight how association rules can uncover hidden purchasing patterns that may not be obvious at first glance. Although this dataset was synthetic, the methodology is directly applicable to real-world retail environments. For example, supermarkets could use such insights for **product placement** (e.g., positioning pasta near tea), **targeted promotions**, or **cross-selling strategies**. The synthetic nature of our data means that the rules are illustrative rather than business-critical, but they still effectively demonstrate the practical value of market basket analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
