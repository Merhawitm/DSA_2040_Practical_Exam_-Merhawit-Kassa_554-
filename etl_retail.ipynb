{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c99102",
   "metadata": {},
   "source": [
    "### Step 1 â€“ Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b1fd9a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in c:\\users\\admin\\anaconda3\\lib\\site-packages (37.5.3)\n",
      "Requirement already satisfied: tzdata in c:\\users\\admin\\anaconda3\\lib\\site-packages (from faker) (2023.3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3632a3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   InvoiceNo StockCode       Description  Quantity InvoiceDate  UnitPrice  \\\n",
      "0      40330     jE690   Prevent Station         7  2024-09-21      79.37   \n",
      "1      84535     dh830  Conference Short         5  2025-04-06      55.73   \n",
      "2      28647     TR953        Lead Stock        34  2023-09-07      44.10   \n",
      "3      12264     kh598       Section War        44  2023-09-16      80.80   \n",
      "4      38327     AN786        Small Save        18  2024-10-22      52.04   \n",
      "\n",
      "   CustomerID                                            Country  \n",
      "0          34                                            Bolivia  \n",
      "1          59                                         Cape Verde  \n",
      "2          42  British Indian Ocean Territory (Chagos Archipe...  \n",
      "3          64                               Netherlands Antilles  \n",
      "4          17                                 Russian Federation  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 1: EXTRACT DATA\n",
    "# Import required libraries\n",
    "import pandas as pd        # For handling and manipulating tabular data\n",
    "import numpy as np         # For generating random numbers and arrays\n",
    "from faker import Faker    # For creating fake but realistic-looking data\n",
    "from datetime import datetime, timedelta  # For working with dates\n",
    "\n",
    "def generate_synthetic_data(num_rows=1000):\n",
    "    \"\"\"\n",
    "    Generates synthetic retail sales data using Faker and NumPy.\n",
    "    The data structure mimics the UCI Online Retail dataset.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    num_rows : int\n",
    "        Number of rows (records) to generate. Default = 1000.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A DataFrame containing the generated synthetic sales data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize Faker object for creating fake values\n",
    "    fake = Faker()\n",
    "\n",
    "    # Container to store generated rows\n",
    "    data = []\n",
    "\n",
    "    # Define the start and end dates for random date generation\n",
    "    start_date = datetime(2023, 8, 12)\n",
    "    end_date = datetime(2025, 8, 12)\n",
    "\n",
    "    # Calculate total number of days in the range for date randomization\n",
    "    date_range = (end_date - start_date).days\n",
    "\n",
    "    # Loop to generate each record\n",
    "    for _ in range(num_rows):\n",
    "        # Generate random invoice number (5 digits)\n",
    "        invoice_no = fake.random_int(min=10000, max=99999)\n",
    "\n",
    "        # Generate random stock code (two letters + three digits)\n",
    "        stock_code = fake.bothify(text='??###')\n",
    "\n",
    "        # Create a fake product description by combining two words\n",
    "        description = fake.word().capitalize() + \" \" + fake.word().capitalize()\n",
    "\n",
    "        # Generate a quantity between 1 and 50\n",
    "        quantity = np.random.randint(1, 50)\n",
    "\n",
    "        # Generate a random date within the given range\n",
    "        invoice_date = start_date + timedelta(days=np.random.randint(0, date_range))\n",
    "\n",
    "        # Generate a unit price between 1 and 100 (rounded to 2 decimal places)\n",
    "        unit_price = round(np.random.uniform(1, 100), 2)\n",
    "\n",
    "        # Random customer ID between 1 and 100 (100 unique customers)\n",
    "        customer_id = np.random.randint(1, 101)\n",
    "\n",
    "        # Generate a random country name\n",
    "        country = fake.country()\n",
    "\n",
    "        # Append the generated record to the list\n",
    "        data.append([invoice_no, stock_code, description, quantity, invoice_date, unit_price, customer_id, country])\n",
    "\n",
    "    # Define column names similar to the original Online Retail dataset\n",
    "    columns = [\"InvoiceNo\", \"StockCode\", \"Description\", \"Quantity\", \"InvoiceDate\", \"UnitPrice\", \"CustomerID\", \"Country\",]\n",
    "\n",
    "    # Convert the list of records into a pandas DataFrame\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Generate and preview the synthetic dataset\n",
    "df = generate_synthetic_data()\n",
    "\n",
    "# Display the first 5 rows to verify data structure\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "73c2b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    " #  Save the generated dataset to CSV \n",
    "df.to_csv(\"synthetic_retail_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5da58b",
   "metadata": {},
   "source": [
    "### Step 2 â€“ Transform\n",
    "### Clean, calculate new fields, filter, and create dimension-like summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a04ef305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Sales Data:\n",
      "    InvoiceNo StockCode       Description  Quantity InvoiceDate  UnitPrice  \\\n",
      "0      40330     jE690   Prevent Station         7  2024-09-21      79.37   \n",
      "1      84535     dh830  Conference Short         5  2025-04-06      55.73   \n",
      "4      38327     AN786        Small Save        18  2024-10-22      52.04   \n",
      "5      50479     NB552         Them Grow         1  2025-07-07      21.27   \n",
      "7      70186     Db875      Project Test        26  2025-07-17      11.92   \n",
      "\n",
      "   CustomerID             Country  TotalSales  \n",
      "0          34             Bolivia      555.59  \n",
      "1          59          Cape Verde      278.65  \n",
      "4          17  Russian Federation      936.72  \n",
      "5          23         Isle of Man       21.27  \n",
      "7         100        Saint Helena      309.92  \n",
      "\n",
      "Customer Summary:\n",
      "    CustomerID  TotalSales      Country\n",
      "0           1     4193.23         Oman\n",
      "1           2     2981.42         Oman\n",
      "2           3    11521.61   Mauritania\n",
      "3           4     8097.38  Philippines\n",
      "4           5     5872.65     Colombia\n",
      "\n",
      "Time Dimension:\n",
      "   InvoiceDate  Year  Month  Quarter\n",
      "0  2024-09-21  2024      9        3\n",
      "1  2025-04-06  2025      4        2\n",
      "4  2024-10-22  2024     10        4\n",
      "5  2025-07-07  2025      7        3\n",
      "7  2025-07-17  2025      7        3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 2: TRANSFORM DATA\n",
    "\n",
    "# Ensure InvoiceDate is datetime\n",
    "df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])\n",
    "\n",
    "# Add TotalSales column\n",
    "df[\"TotalSales\"] = df[\"Quantity\"] * df[\"UnitPrice\"]\n",
    "\n",
    "# Remove outliers\n",
    "df = df[(df[\"Quantity\"] >= 0) & (df[\"UnitPrice\"] > 0)]\n",
    "\n",
    "# Filter last year (Aug 12, 2024 to Aug 12, 2025)\n",
    "filter_start = datetime(2024, 8, 12)\n",
    "filter_end = datetime(2025, 8, 12)\n",
    "df_last_year = df[(df[\"InvoiceDate\"] >= filter_start) & (df[\"InvoiceDate\"] <= filter_end)]\n",
    "\n",
    "# Create Customer summary\n",
    "customer_summary = df_last_year.groupby(\"CustomerID\").agg({\n",
    "    \"TotalSales\": \"sum\",\n",
    "    \"Country\": \"first\"\n",
    "}).reset_index()\n",
    "\n",
    "# Create Time dimension table\n",
    "time_dim = df_last_year[[\"InvoiceDate\"]].drop_duplicates().copy()\n",
    "time_dim[\"Year\"] = time_dim[\"InvoiceDate\"].dt.year\n",
    "time_dim[\"Month\"] = time_dim[\"InvoiceDate\"].dt.month\n",
    "time_dim[\"Quarter\"] = time_dim[\"InvoiceDate\"].dt.quarter\n",
    "\n",
    "print(\"Transformed Sales Data:\\n\", df_last_year.head())\n",
    "print(\"\\nCustomer Summary:\\n\", customer_summary.head())\n",
    "print(\"\\nTime Dimension:\\n\", time_dim.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288d0a8",
   "metadata": {},
   "source": [
    "### Step 3 â€“ Load\n",
    " Store the transformed data into SQLite database (retail_dw.db)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "08e30bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into retail_dw.db\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 3: LOAD DATA\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# Connect to SQLite database (creates file if it doesn't exist)\n",
    "conn = sqlite3.connect(\"retail_dw.db\")\n",
    "\n",
    "# Load tables into database\n",
    "df_last_year.to_sql(\"SalesFact\", conn, if_exists=\"replace\", index=False)\n",
    "customer_summary.to_sql(\"CustomerDim\", conn, if_exists=\"replace\", index=False)\n",
    "time_dim.to_sql(\"TimeDim\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "\n",
    "print(\"Data successfully loaded into retail_dw.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e294cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 4 â€“ Combine into ETL Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a952bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Extracting...\n",
      "Rows Extracted: 1000\n",
      "ðŸ”¹ Transforming...\n",
      "Rows after transform: 510\n",
      "ðŸ”¹ Loading into DB...\n",
      " ETL Complete!\n"
     ]
    }
   ],
   "source": [
    "def run_etl():\n",
    "\n",
    "    # EXTRACT PHASE\n",
    "   \n",
    "    print(\"ðŸ”¹ Extracting...\")\n",
    "    # Generate synthetic retail data (mimics UCI Online Retail dataset)\n",
    "    df = generate_synthetic_data()\n",
    "    print(f\"Rows Extracted: {len(df)}\")  # Log total rows extracted\n",
    "\n",
    "    # TRANSFORM PHASE\n",
    "  \n",
    "    print(\"ðŸ”¹ Transforming...\")\n",
    "\n",
    "    # Convert InvoiceDate column to datetime for proper filtering and grouping\n",
    "    df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])\n",
    "\n",
    "    # Calculate TotalSales as Quantity Ã— UnitPrice\n",
    "    df[\"TotalSales\"] = df[\"Quantity\"] * df[\"UnitPrice\"]\n",
    "\n",
    "    # Remove invalid rows where Quantity is negative or UnitPrice is zero/negative\n",
    "    df = df[(df[\"Quantity\"] >= 0) & (df[\"UnitPrice\"] > 0)]\n",
    "\n",
    "    # Define date range for \"last year\" sales (exam's reference date: Aug 12, 2025)\n",
    "    filter_start = datetime(2024, 8, 12)\n",
    "    filter_end = datetime(2025, 8, 12)\n",
    "\n",
    "    # Filter dataset for only the sales in the last year\n",
    "    df_last_year = df[(df[\"InvoiceDate\"] >= filter_start) & (df[\"InvoiceDate\"] <= filter_end)]\n",
    "\n",
    "    # Create a Customer Dimension table:\n",
    "    # - Group by CustomerID\n",
    "    # - Aggregate total sales per customer\n",
    "    # - Keep the first encountered country (assuming one per customer)\n",
    "    customer_summary = df_last_year.groupby(\"CustomerID\").agg({\n",
    "        \"TotalSales\": \"sum\",\n",
    "        \"Country\": \"first\"\n",
    "    }).reset_index()\n",
    "\n",
    "    # Create a Time Dimension table:\n",
    "    # - Unique dates from last year's sales\n",
    "    # - Extract Year, Month, and Quarter for analysis\n",
    "    time_dim = df_last_year[[\"InvoiceDate\"]].drop_duplicates().copy()\n",
    "    time_dim[\"Year\"] = time_dim[\"InvoiceDate\"].dt.year\n",
    "    time_dim[\"Month\"] = time_dim[\"InvoiceDate\"].dt.month\n",
    "    time_dim[\"Quarter\"] = time_dim[\"InvoiceDate\"].dt.quarter\n",
    "\n",
    "    print(f\"Rows after transform: {len(df_last_year)}\")  # Log rows after filtering\n",
    "\n",
    "    # LOAD PHASE\n",
    "   \n",
    "    print(\"ðŸ”¹ Loading into DB...\")\n",
    "\n",
    "    # Connect to (or create) SQLite database file retail_dw.db\n",
    "    conn = sqlite3.connect(\"retail_dw.db\")\n",
    "\n",
    "    # Load fact table: SalesFact (last year's cleaned sales data)\n",
    "    df_last_year.to_sql(\"SalesFact\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "    # Load dimension table: CustomerDim\n",
    "    customer_summary.to_sql(\"CustomerDim\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "    # Load dimension table: TimeDim\n",
    "    time_dim.to_sql(\"TimeDim\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "    # Close database connection\n",
    "    conn.close()\n",
    "\n",
    "    print(\" ETL Complete!\")  # Log completion message\n",
    "\n",
    "\n",
    "# Run full ETL process\n",
    "run_etl()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e87c22c",
   "metadata": {},
   "source": [
    "### Step 4: the full ETL function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "00c05b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ STEP 1: Extracting data...\n",
      " Extracted 1000 rows.\n",
      "ðŸ”¹ STEP 2: Transforming data...\n",
      " After transformation: 505 rows in fact table.\n",
      "ðŸ”¹ STEP 3: Loading data into SQLite database...\n",
      "Data successfully loaded into retail_dw.db\n",
      "\n",
      " ETL PROCESS SUMMARY\n",
      " - Rows Extracted: 1000\n",
      " - Rows After Transformation (Fact Table): 505\n",
      " - CustomerDim Rows: 100\n",
      " - TimeDim Rows: 276\n",
      " ETL Completed Successfully!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3  # For database connection\n",
    "\n",
    "def run_etl():\n",
    "    \"\"\"\n",
    "    Runs the full ETL (Extract, Transform, Load) process for the synthetic retail dataset.\n",
    "    Logs the number of rows processed at each stage.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # EXTRACT\n",
    "  \n",
    "    print(\"ðŸ”¹ STEP 1: Extracting data...\")\n",
    "    df = generate_synthetic_data()  # Call our extraction function\n",
    "    print(f\" Extracted {len(df)} rows.\")\n",
    "\n",
    "   \n",
    "    # TRANSFORM\n",
    " \n",
    "    print(\"ðŸ”¹ STEP 2: Transforming data...\")\n",
    "\n",
    "    # Convert InvoiceDate to datetime type\n",
    "    df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])\n",
    "\n",
    "    # Create a new column for total sales value\n",
    "    df[\"TotalSales\"] = df[\"Quantity\"] * df[\"UnitPrice\"]\n",
    "\n",
    "    # Remove invalid rows: Quantity < 0 or UnitPrice <= 0\n",
    "    df = df[(df[\"Quantity\"] >= 0) & (df[\"UnitPrice\"] > 0)]\n",
    "\n",
    "    # Filter for the last year (from 2024-08-12 to 2025-08-12)\n",
    "    filter_start = datetime(2024, 8, 12)\n",
    "    filter_end = datetime(2025, 8, 12)\n",
    "    df_last_year = df[(df[\"InvoiceDate\"] >= filter_start) & (df[\"InvoiceDate\"] <= filter_end)]\n",
    "\n",
    "    # Create Customer Dimension (summary)\n",
    "    customer_summary = df_last_year.groupby(\"CustomerID\").agg({\n",
    "        \"TotalSales\": \"sum\",\n",
    "        \"Country\": \"first\"  # Keep first country per customer\n",
    "    }).reset_index()\n",
    "\n",
    "    # Create Time Dimension (unique dates with year, month, quarter)\n",
    "    time_dim = df_last_year[[\"InvoiceDate\"]].drop_duplicates().copy()\n",
    "    time_dim[\"Year\"] = time_dim[\"InvoiceDate\"].dt.year\n",
    "    time_dim[\"Month\"] = time_dim[\"InvoiceDate\"].dt.month\n",
    "    time_dim[\"Quarter\"] = time_dim[\"InvoiceDate\"].dt.quarter\n",
    "\n",
    "    print(f\" After transformation: {len(df_last_year)} rows in fact table.\")\n",
    "\n",
    "\n",
    "    # LOAD\n",
    "  \n",
    "    print(\"ðŸ”¹ STEP 3: Loading data into SQLite database...\")\n",
    "    conn = sqlite3.connect(\"retail_dw.db\")  # Create DB file\n",
    "    df_last_year.to_sql(\"SalesFact\", conn, if_exists=\"replace\", index=False)  # Fact table\n",
    "    customer_summary.to_sql(\"CustomerDim\", conn, if_exists=\"replace\", index=False)  # Customer dimension\n",
    "    time_dim.to_sql(\"TimeDim\", conn, if_exists=\"replace\", index=False)  # Time dimension\n",
    "    conn.close()\n",
    "    print(\"Data successfully loaded into retail_dw.db\")\n",
    "\n",
    "\n",
    "    # LOG SUMMARY\n",
    "    \n",
    "    print(\"\\n ETL PROCESS SUMMARY\")\n",
    "    print(f\" - Rows Extracted: {len(df)}\")\n",
    "    print(f\" - Rows After Transformation (Fact Table): {len(df_last_year)}\")\n",
    "    print(f\" - CustomerDim Rows: {len(customer_summary)}\")\n",
    "    print(f\" - TimeDim Rows: {len(time_dim)}\")\n",
    "    print(\" ETL Completed Successfully!\")\n",
    "\n",
    "# Run the ETL process\n",
    "run_etl()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d6680",
   "metadata": {},
   "source": [
    "### Task 3: OLAP Queries\n",
    "1. Roll-up: Total Sales by Country and Quarter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "75fe221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Roll-up: Total sales by Country & Quarter ---\n",
      "               Country  Quarter  TotalSales\n",
      "0          Afghanistan        1     1098.30\n",
      "1          Afghanistan        2     1310.36\n",
      "2              Albania        4      591.63\n",
      "3              Algeria        2       69.69\n",
      "4              Algeria        3      664.09\n",
      "..                 ...      ...         ...\n",
      "386  Wallis and Futuna        1      285.48\n",
      "387  Wallis and Futuna        4      775.68\n",
      "388              Yemen        3     1076.09\n",
      "389           Zimbabwe        1     1597.32\n",
      "390           Zimbabwe        4     1949.60\n",
      "\n",
      "[391 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to your SQLite database\n",
    "conn = sqlite3.connect(\"retail_dw.db\")\n",
    "\n",
    "with sqlite3.connect(\"retail_dw.db\") as conn:\n",
    "    # Define SQL query to aggregate sales by country and quarter\n",
    "    query_rollup_fixed = \"\"\"\n",
    "    SELECT \n",
    "        sf.Country,               -- Select country from SalesFact table\n",
    "        td.Quarter,               -- Select quarter from TimeDim table\n",
    "        SUM(sf.TotalSales) AS TotalSales  -- Calculate total sales for each group\n",
    "    FROM SalesFact sf\n",
    "    JOIN TimeDim td ON sf.InvoiceDate = td.InvoiceDate  -- Join on InvoiceDate to get quarter info\n",
    "    GROUP BY sf.Country, td.Quarter                    -- Group results by country and quarter\n",
    "    ORDER BY sf.Country, td.Quarter;                   -- Sort output by country and quarter\n",
    "    \"\"\"\n",
    "    # Execute the query and load results into a DataFrame\n",
    "    rollup_df = pd.read_sql_query(query_rollup_fixed, conn)\n",
    "    # Print the roll-up results\n",
    "    print(\"\\n--- Roll-up: Total sales by Country & Quarter ---\")\n",
    "    print(rollup_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cec763",
   "metadata": {},
   "source": [
    " 2ï¸, Drill-down: Monthly Sales for a Specific Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "defc3762",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Drill-down: Monthly sales for Belarus ---\n",
      "Empty DataFrame\n",
      "Columns: [Year, Month, MonthlySales]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Connect to the SQLite database using the existing connection object 'conn'\n",
    "# (conn is already defined in the notebook and points to 'retail_dw.db')\n",
    "\n",
    "# Define the SQL query for drill-down: monthly sales for the selected country (country_name)\n",
    "# This query:\n",
    "# - Selects Year and Month from the TimeDim table\n",
    "# - Sums TotalSales from the SalesFact table for each month\n",
    "# - Joins SalesFact and TimeDim on InvoiceDate to get month/year info\n",
    "# - Filters for rows where SalesFact.Country matches the given country_name\n",
    "# - Groups results by Year and Month\n",
    "# - Orders results by Year and Month for chronological output\n",
    "query_drilldown_fixed = \"\"\"\n",
    "    SELECT td.Year,                    -- Extract year from TimeDim\n",
    "           td.Month,                   -- Extract month from TimeDim\n",
    "           SUM(sf.TotalSales) AS MonthlySales  -- Aggregate total sales for the month\n",
    "    FROM SalesFact sf                  -- Use SalesFact as main table\n",
    "    JOIN TimeDim td ON sf.InvoiceDate = td.InvoiceDate  -- Join to get time attributes\n",
    "    WHERE sf.Country = ?               -- Filter for the selected country\n",
    "    GROUP BY td.Year, td.Month         -- Group by year and month\n",
    "    ORDER BY td.Year, td.Month;        -- Sort results chronologically\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query using pandas read_sql_query\n",
    "# - Pass the query string\n",
    "# - Use the existing connection 'conn'\n",
    "# - Provide the country_name as a parameter to the query (for WHERE clause)\n",
    "drilldown_df = pd.read_sql_query(query_drilldown_fixed, conn, params=(country_name,))\n",
    "\n",
    "# Print a header to indicate the drill-down results for the selected country\n",
    "print(f\"\\n--- Drill-down: Monthly sales for {country_name} ---\")\n",
    "\n",
    "# Display the resulting DataFrame containing monthly sales\n",
    "print(drilldown_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a9e93",
   "metadata": {},
   "source": [
    "3ï¸, Slice: Total Sales by Category (focus on Electronics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "13240b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Slice: Top 10 product descriptions by total sales ---\n",
      "       Description  DescriptionSales\n",
      "0     College Blue           4837.77\n",
      "1    Eight Himself           4658.64\n",
      "2       Have Party           4632.96\n",
      "3       East Field           4577.76\n",
      "4  Measure Develop           4486.15\n",
      "5       Think Lead           4236.60\n",
      "6      Create Loss           4231.35\n",
      "7   Measure Policy           4200.24\n",
      "8        Oil Piece           4126.13\n",
      "9   Artist Evening           4015.68\n"
     ]
    }
   ],
   "source": [
    "# OLAP Slice Query: Top 10 Product Descriptions by Total Sales\n",
    "\n",
    "# The following code executes an OLAP \"slice\" query to find the top 10 product descriptions\n",
    "# with the highest total sales in the SalesFact table of the retail_dw.db SQLite database.\n",
    "\n",
    "# The connection object 'conn' is already available in the notebook.\n",
    "\n",
    "# Define the SQL query:\n",
    "# - Selects the Description column (product description)\n",
    "# - Sums the TotalSales for each description\n",
    "# - Groups results by Description\n",
    "# - Orders by total sales in descending order\n",
    "# - Limits output to top 10 descriptions\n",
    "query_slice_fixed = \"\"\"\n",
    "    SELECT Description,                      -- Product description\n",
    "           SUM(TotalSales) AS DescriptionSales  -- Total sales for each description\n",
    "    FROM SalesFact\n",
    "    GROUP BY Description                      -- Group by product description\n",
    "    ORDER BY DescriptionSales DESC            -- Sort by sales descending\n",
    "    LIMIT 10;                                 -- Only top 10 results\n",
    "    \"\"\"\n",
    "\n",
    "# Execute the query using pandas read_sql_query:\n",
    "# - Pass the query string\n",
    "# - Use the existing SQLite connection 'conn'\n",
    "slice_df = pd.read_sql_query(query_slice_fixed, conn)\n",
    "\n",
    "# Print a header for clarity\n",
    "print(\"\\n--- Slice: Top 10 product descriptions by total sales ---\")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(slice_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b2021b",
   "metadata": {},
   "source": [
    " Plot: Bar chart of total sales by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974adb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Connect to your SQLite database\n",
    "conn = sqlite3.connect(\"retail_dw.db\")\n",
    "\n",
    "# Query: Total sales by country\n",
    "query_country_sales = \"\"\"\n",
    "SELECT c.Country,\n",
    "       SUM(s.TotalSales) AS TotalSales\n",
    "FROM SalesFact s\n",
    "JOIN CustomerDim c ON s.CustomerID = c.CustomerID\n",
    "GROUP BY c.Country\n",
    "ORDER BY TotalSales DESC;\n",
    "\"\"\"\n",
    "\n",
    "country_sales_df = pd.read_sql_query(query_country_sales, conn)\n",
    "conn.close()\n",
    "\n",
    "# Plot: Bar chart of total sales by country\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(country_sales_df['Country'], country_sales_df['TotalSales'], color='skyblue', edgecolor='black')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel(\"Country\")\n",
    "plt.ylabel(\"Total Sales\")\n",
    "plt.title(\"Total Sales by Country\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save as PNG\n",
    "plt.savefig(\"total_sales_by_country.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Chart saved as total_sales_by_country.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
